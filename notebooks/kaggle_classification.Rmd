---
title: "Classification on Brazilian elections"
author: "JosÃ© Benardi de Souza Nunes"
output:
  html_notebook:
    toc: yes
    toc_float: yes
  html_document:
    df_print: paged
    toc: yes
    toc_float: yes
---


```{r}
library(dataPreparation)
library(tidyverse)
library(MLmetrics)
library(ggmosaic)
library(GGally)
library(caret)
library(here)
```

# Data Overview

## Loading Data

```{r}
readr::read_csv(here::here('data/train_class.csv'),
                progress = FALSE,
                local=readr::locale("br"),
                col_types = cols(ano = col_integer(),
                                 sequencial_candidato = col_character(),
                                 quantidade_doacoes = col_integer(),
                                 quantidade_doadores = col_integer(),
                                 total_receita = col_double(),
                                 media_receita = col_double(),
                                 recursos_de_outros_candidatos.comites = col_double(),
                                 recursos_de_pessoas_fisicas = col_double(),
                                 recursos_de_pessoas_juridicas = col_double(),
                                 recursos_proprios = col_double(),
                                 `recursos_de_partido_politico` = col_double(),
                                 quantidade_despesas = col_integer(),
                                 quantidade_fornecedores = col_integer(),
                                 total_despesa = col_double(),
                                 media_despesa = col_double(),
                                 situacao = col_character(),
                                 .default = col_character())) %>%
  mutate(sequencial_candidato = as.numeric(sequencial_candidato),
         estado_civil = as.factor(estado_civil),
         ocupacao = as.factor(ocupacao),
         situacao = as.factor(situacao),
         partido = as.factor(partido),
         grau = as.factor(grau),
         sexo = as.factor(sexo),
         uf = as.factor(uf)) -> data

data %>%
  glimpse()
```

```{r}
data %>%
  map_df(function(x) sum(is.na(x))) %>%
  gather(feature, num_nulls) %>%
  arrange(desc(num_nulls))
```

## Data Exploration

### Imbalance on class distribution

```{r}
data %>%
  ggplot(aes(situacao)) +
  geom_bar()
```

#### There's a strong imbalance in the class distribution of the dataset

* This imbalance can lead to a bias in the model that will learn to overlook the less frequent classes. Such bias can have a negative impact in the model generalization and its performance.
    + We can restore balance by removing instances from the most frequent class $undersampling$.
    + We can restore balance by adding instances from the most frequent class $oversampling$.

```{r}
data %>% 
  select(-ano,
         -sequencial_candidato,
         -nome) %>%
  select(
    quantidade_doacoes,
    quantidade_doadores,
    total_receita,
    media_receita,
    recursos_de_outros_candidatos.comites,
    recursos_de_pessoas_fisicas,
    recursos_de_pessoas_juridicas,
    recursos_proprios,
    `recursos_de_partido_politico`) %>%
  na.omit() %>%
  ggcorr(palette = "RdBu", label = TRUE,
       hjust = 0.95, label_size = 3,size = 3,
       nbreaks = 5, layout.exp = 5) +
  ggtitle("Correlation plot for employed variables")
```

```{r}
data %>%
  ggplot(aes(situacao,recursos_proprios)) +
  geom_boxplot() + 
  coord_flip()
```

```{r}
data %>%
  ggplot(aes(situacao,
             recursos_de_partido_politico)) +
  geom_boxplot() + 
  coord_flip()
```

```{r}
data %>%
  ggplot(aes(situacao,
             recursos_de_outros_candidatos.comites)) +
  geom_boxplot() + 
  coord_flip()
```

```{r}
data %>%
  ggplot(aes(situacao,
             recursos_de_pessoas_fisicas)) +
  geom_boxplot() + 
  coord_flip()
```

```{r}
data %>%
  ggplot(aes(situacao,
             recursos_de_pessoas_juridicas)) +
  geom_boxplot() + 
  coord_flip()
```

```{r}
data %>%
  ggplot(aes(situacao,
             quantidade_doacoes)) +
  geom_boxplot() + 
  coord_flip()
```

```{r}
data %>%
  ggplot(aes(situacao,
             quantidade_doadores)) +
  geom_boxplot() + 
  coord_flip()
```

```{r}
data %>%
  ggplot(aes(situacao,
             media_receita)) +
  geom_boxplot() + 
  coord_flip()
```

```{r}
data %>%
  ggplot(aes(situacao,
             total_receita)) +
  geom_boxplot() + 
  coord_flip()
```

```{r}
data %>%
ggplot() +
   geom_mosaic(aes(x = product(sexo, situacao),
                   fill=sexo)) +
   theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())
```

```{r}
data %>%
ggplot() +
   geom_mosaic(aes(x = product(grau, situacao),
                   fill=grau)) +
   theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())
```

```{r}
data %>%
ggplot() +
   geom_mosaic(aes(x = product(estado_civil, situacao),
                   fill=estado_civil)) +
   theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())
```

### Splitting data and Encoding

```{r}
set.seed(107)

data$id <- 1:nrow(data)

data %>% 
  dplyr::sample_frac(.8) -> train

cat("#### Train Shape",
    "\n##### Observations: ",nrow(train),
    "\n##### Variables: ",ncol(train))
```

```{r}
dplyr::anti_join(data, 
                 train, 
                 by = 'id') -> test

cat("#### Test Shape",
    "\n##### Observations: ",nrow(test),
    "\n##### Variables: ",ncol(test))
```

```{r results='asis'}
encoding <- build_encoding(dataSet = data,
                          cols = c("uf","sexo","grau","ocupacao",
                                   "partido","estado_civil"),
                          verbose = F)

train <- one_hot_encoder(dataSet = train,
                          encoding = encoding,
                          drop = TRUE,
                          verbose = F)

cat("#### Train Shape",
    "\n##### Observations: ",nrow(train),
    "\n##### Variables: ",ncol(train))
```

```{r}
test <- one_hot_encoder(dataSet = test,
                          encoding = encoding,
                          drop = TRUE,
                          verbose = F)

cat("#### Data Shape",
    "\n##### Observations: ",nrow(test),
    "\n##### Variables: ",ncol(test))
```

## Near Zero Variance Predictors

```{r}
train %>%
  nearZeroVar(saveMetrics = TRUE) %>%
  tibble::rownames_to_column("variable") %>%
  filter(nzv == T) %>% 
  pull(variable) -> near_zero_vars

train %>% 
    select(-one_of(near_zero_vars)) %>%
    select(-ano,-nome,-id,-sequencial_candidato) -> train

test %>%
    select(-one_of(near_zero_vars)) %>%
    select(-ano,-nome,-id,-sequencial_candidato) -> test


near_zero_vars %>% 
  glimpse() 
```

## Scale and Center

```{r}
train %>%
  preProcess(.,method = c("center","scale")) -> processParams

processParams %>%
  predict(.,train) -> train 

processParams %>% 
  predict(.,test) -> test 

processParams
```

# Logistic Regression 

```{r}
f1 <- function(data, lev = NULL, model = NULL) {
  f1_val <- F1_Score(y_pred = data$pred,
                     y_true = data$obs,
                     positive = lev[1])
  c(F1 = f1_val)
}

F_Measure <- function(expected, predicted, ...) {
  data.frame(expected=expected,
             prediction=predicted) %>%
      mutate(TP = ifelse(expected == "eleito" & 
                         prediction == "eleito",1,0),
             TN = ifelse(expected == "nao_eleito" &
                         prediction == "nao_eleito",1,0),
             FN = ifelse(expected == "eleito" &
                         prediction == "nao_eleito",1,0),
             FP = ifelse(expected == "nao_eleito" &
                         prediction == "eleito",1,0)) -> result
  result  %>%
    summarize(TP = sum(TP),
              TN = sum(TN),
              FP = sum(FP),
              FN = sum(FN)) %>%
    mutate(recall = TP / (TP + FN),
           precision = TP / (TP + FP),
           accuracy = (TP + TN)/(TP + TN + FP + FN),
           f_measure = 2 * (precision * recall) / (precision + recall)) -> result
  
  return(result)
}
```


```{r}
rlGrid <- expand.grid( cost = c(200,2,0.02),
                       loss = c("L1", "L2_dual", "L2_primal"),
                       epsilon = c(0.001,0.01) )
train %>%
  caret::train(situacao ~ .,
               data= .,
               method = "regLogistic",
               metric = "F1",
               trControl = trainControl(method = "boot",
                                        classProbs = TRUE,
                                        summaryFunction = f1,
                                        savePredictions = "final"),
               tuneGrid = rlGrid) -> model.rl

model.rl
```

```{r}
model.rl %>%
  varImp() %$%
  importance %>%
  as.data.frame() %>%
  rownames_to_column(var="Feature") %>%
  mutate(Feature = tolower(Feature)) %>%
  ggplot() +
  geom_col(aes(x = reorder(Feature,eleito),y = eleito),
           position = position_dodge(width=0.8),width=0.6) + 
  labs(x="Feature", y="Overall Importance") +
  coord_flip()
```

## Quality metric

### Train and Validation

```{r}
model.rl %$% 
  pred %>% 
  F_Measure(expected = .$obs,
            predicted = .$pred)
```

### Test

```{r}
test %>%
  select(-situacao) %>%
  predict(object=model.rl,.) %>%
  F_Measure(test$situacao,.)
```

# K nearest neighbours

```{r}
neighborsGrid <- expand.grid(.k = seq(from=1, to=50, by=1))

train %>%
  train(situacao ~ .,
        data = .,
        metric = "F1",
        method = "knn",
        na.action = na.omit,
        tuneGrid = neighborsGrid,
        trControl = trainControl(method = "boot",
                                 classProbs = TRUE,
                                 summaryFunction = f1,
                                 savePredictions = "final")) -> model.knn

model.knn
```

```{r}
model.knn %>%
  varImp() %$%
  importance %>%
  as.data.frame() %>%
  rownames_to_column(var="Feature") %>%
  mutate(Feature = tolower(Feature)) %>%
  ggplot() +
  geom_col(aes(x = reorder(Feature,eleito),y = eleito),
           position = position_dodge(width=0.8),width=0.6) + 
  labs(x="Feature", y="Overall Importance") +
  coord_flip()
```


## Quality metric

### Train and Validation

```{r}
model.knn %$% 
  pred %>% 
  F_Measure(expected = .$obs,
            predicted = .$pred)
```

### Test

```{r}
test %>%
  select(-situacao) %>%
  predict(object=model.knn,.) %>%
  F_Measure(test$situacao,.)
```

# Decision Tree

```{r}
rpart.grid <- expand.grid(.cp = seq(from=0, to=0.1, by=0.005))

caret::train(x = select(train, -situacao),
             y = train$situacao,
             metric = "F1",
             method = "rpart",
             na.action = na.omit,
             tuneGrid = rpart.grid,
             trControl = trainControl(method = "boot",
                                      classProbs = TRUE,
                                      summaryFunction = f1,
                                      savePredictions = "final")) -> model.tree

model.tree
```

```{r}
model.tree %>%
  varImp() %$%
  importance %>%
  as.data.frame() %>%
  rownames_to_column(var="Feature") %>%
  mutate(Feature = tolower(Feature)) %>%
  ggplot() +
  geom_col(aes(x = reorder(Feature,Overall),y = Overall),
           position = position_dodge(width=0.8),width=0.6) + 
  labs(x="Feature", y="Overall Importance") +
  coord_flip()
```


## Quality metric

### Train and Validation

```{r}
model.tree %$% 
  pred %>% 
  F_Measure(expected = .$obs,
            predicted = .$pred)
```

### Test

```{r}
test %>%
  select(-situacao) %>%
  predict(object=model.tree,.) %>%
  F_Measure(test$situacao,.)
```

